{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple AR Program\n",
    "1) Compute point correspondences (2D and AR tag) <br>\n",
    "2) Estimate the pose of the camera <br>\n",
    "3) Project 3D content to the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputting the video frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_PATH = \"data/apriltagims/*\"\n",
    "\n",
    "video_frame_paths = glob.glob(FRAMES_PATH)\n",
    "video_frame_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_points = 1.0e+02 * np.array([[1.981631469726562,3.165294189453125],\n",
    "                                    [3.786268920898438,3.424402770996094],\n",
    "                                    [4.036800842285157,1.686005859375000],\n",
    "                                    [2.333528289794922,1.491907043457031]])\n",
    "\n",
    "K = 1.0e+02 * np.array([[7.661088867187500, 0, 3.139585628047498],\n",
    "                        [0, 7.699354248046875,  2.503607131410900],\n",
    "                        [0 ,                  0,   0.010000000000000 ]])\n",
    "num_frames = 166\n",
    "tag_width = 0.13;\n",
    "tag_height = 0.13;\n",
    "cube_depth = 0.13;\n",
    "\n",
    "corner_pts = np.array([[  tag_width/2,  tag_height/2],\n",
    "               [-tag_width/2,  tag_height/2],\n",
    "               [-tag_width/2, -tag_height/2],\n",
    "               [tag_width/2, -tag_height/2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement KLT Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_imgs = []\n",
    "\n",
    "for frame_path in video_frame_paths:\n",
    "    frame = cv2.imread(frame_path)\n",
    "    video_imgs.append(frame)\n",
    "    \n",
    "video_imgs=np.array(video_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLTtrack():\n",
    "    def __init__(self,imglist,trackpts):\n",
    "        self.vid = imglist\n",
    "        self.pts = trackpts\n",
    "        # Parameters for lucas kanade optical flow\n",
    "        self.lk_params = dict(winSize  = (31,31),\n",
    "                  maxLevel = 3,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_COUNT, 5, 0.03))\n",
    "\n",
    "    def pointTracker(self):\n",
    "        # Create some random colors\n",
    "        color = np.random.randint(0,255,(self.pts.shape[0],3))\n",
    "        # Take first frame and find corners in it\n",
    "        old_frame = self.vid[0,:,:,:]\n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        p0 = np.floor(self.pts).reshape(-1,1,2).astype(np.float32)\n",
    "        \n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        corners = []\n",
    "        corners.append(self.pts)\n",
    "\n",
    "        for i in range(1,len(self.vid)):\n",
    "            frame = video_imgs[i,:,:,:]\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # calculate optical flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **self.lk_params)\n",
    "            # Select good points\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "            # draw the tracks\n",
    "            for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "                a,b = new.ravel()\n",
    "                c,d = old.ravel()\n",
    "                mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "                frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "            img = cv2.add(frame,mask)\n",
    "\n",
    "            k = cv2.waitKey(5) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "            # Now update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            corners.append(good_new)\n",
    "            p0 = good_new.reshape(-1,1,2)\n",
    "            \n",
    "        return np.array(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_corners(video_frames, initial_pts):\n",
    "        \n",
    "    tracker = KLTtrack(video_frames, initial_points)\n",
    "    \n",
    "    return tracker.pointTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = track_corners(video_imgs, initial_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homography Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import vectorize, solve_homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pose Estimation (from Homography) of co-planar points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pose_from_homography(H, K):\n",
    "    '''\n",
    "    function for pose prediction of the camera from the homography matrix, given the intrinsics \n",
    "    \n",
    "    :param H(np.array): size(3x3) homography matrix\n",
    "    :param K(np.array): size(3x3) intrinsics of camera\n",
    "    :Return t: size (3 x 1) vector of the translation of the transformation\n",
    "    :Return R: size (3 x 3) matrix of the rotation of the transformation (orthogonal matrix)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #to disambiguate two rotation marices corresponding to the translation matrices (t and -t), \n",
    "    #multiply H by the sign of the z-comp on the t-matrix to enforce the contraint that z-compoment of point\n",
    "    #in-front must be positive and thus obtain a unique rotational matrix\n",
    "    H = H*np.sign(H[2,2])\n",
    "    \n",
    "    #H=K*[R|t]\n",
    "    H_ = np.invert(K)@H\n",
    "    \n",
    "    h1,h2,h3 = H[:,0], H[:1] , H[:,2]\n",
    "    \n",
    "    R_ = np.array((h1,h2,np.cross(h1,h2))).T\n",
    "    \n",
    "    U, S, V = np.linalg(R_)\n",
    "    \n",
    "    R = U@np.array([[1,0,0],\n",
    "                   [0,1,0],\n",
    "                    [0,0,np.linalg.det(U@V.T)]])\n",
    "    \n",
    "    t = h3/np.linalg.norm(h1).reshape(-1,1)\n",
    "    \n",
    "    return R,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(render_points, K, R, t);\n",
    "    '''\n",
    "    function to project world coordinated or renders (virtual) of world coordinate onto image plane\n",
    "    \n",
    "    :param K:size(3x3) intrinsic camera matrix\n",
    "    :param R:size(3x3)\n",
    "    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ar_cube(points, im):\n",
    "    '''\n",
    "    Uses projection equation to create images from points\n",
    "    \n",
    "    :param points(np.array): size(2x8) : projected points to connect\n",
    "    :param im(np.array): size (nxm) to render with the image\n",
    "    \n",
    "    Returns\n",
    "    im_out - (np.array): size(nxm) with the cube drawn on the image\n",
    "    '''\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projecting Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array((a,a,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
